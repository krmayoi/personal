# ğŸ“Š Dow Jones NLP & Portfolio Analysis Pipeline

## Overview
This project is an **endâ€‘toâ€‘end data pipeline** that integrates **financial market data**, **SEC 10â€‘K filings**, and **news sentiment analysis** to extract actionable insights from the Dow Jones Industrial Average (DJIA) constituents.

It combines:
- **Data engineering** â€” automated retrieval, cleaning, and storage of multiâ€‘source datasets
- **Natural Language Processing (NLP)** â€” textual analysis of SEC filings using domainâ€‘specific dictionaries
- **Portfolio analytics** â€” inâ€‘sample simulations, outâ€‘ofâ€‘sample backtesting, and risk metrics
- **Reproducible architecture** â€” modular, configâ€‘driven design for easy extension

The next phase will extend this into **machine learning models** to predict market behaviour from textual and quantitative features.

---

## âœ¨ Features

### 1. Data Acquisition
- **Dow Jones tickers** fetched dynamically from a configurable source
- **Historical market data** via Yahoo Finance
- **SEC 10â€‘K filings** downloaded and stored locally
- **News headlines** scraped for sentiment analysis

### 2. Portfolio Analysis
- Inâ€‘sample simulations with overlapping periods
- Outâ€‘ofâ€‘sample backtesting of the **Max Sharpe** portfolio
- **Value at Risk (VaR)** analysis for equalâ€‘weighted portfolios

### 3. NLP on SEC Filings
- **Uncertainty** score (LM dictionary)
- **Tone** score (positive vs. negative LM words)
- **FOG Index** (text complexity)
- **Flesch Reading Ease** (readability)
- Efficient, cached syllable counting for large documents

### 4. Sentiment Analysis
- Headline sentiment scoring using VADER
- Aggregated compound sentiment per ticker

### 5. Machine Learning Models
- Feature engineering from both quantitative market data and partner-ticker correlations (`feature_engineering.py`)
- Config-driven base ticker selection -- swap `BASE_TICKER` in `config.py` to train on any ticker
- Automated model tuning with `RandomizedSearchCV` + `GridSearchCV` for:
    - Decision Trees
    - Random Forests
    - Gradient Boosting
- Model ranking by combined Accuracy, Precision, and scaled MSE
- Portfolio simulation of ML predictions:
    - Long-short strategy
    - Buy-and-hold benchmark
    - Summary stats: total return, annualized return/volatility, max drawdown
  
--- 

## ğŸ§  ML Workflow

1. Feature Engineering
- Pulls base ticker + most correlated partner ticker
- Generates rolling technical indicators, volume/price trends, and stochastic oscillators
- Merges features into a single aligned dataset
2. Train / Holdout Split
- Dateâ€‘based or fractionâ€‘based split via `split_model_holdout()`
- Holdout period configurable in `ml_train.py` for forwardâ€‘testing
3. Model Selection & Tuning
- Hyperparameter search for each model
- Best models stored in `selector.tuned_models`
4. Evaluation & Simulation
- Metrics on holdout set
- Portfolio backtest with realistic frictions
- Equity curve plots and performance summaries

---

## ğŸ› ï¸ Tech Stack

**Languages & Libraries**
- Python 3.11.9
- `pandas`, `numpy`, `yfinance`, `nltk`, `scikit-learn` (ML phase)
- Custom modules: `data_fetcher`, `portfolio_analysis`, `news_analysis`, `sec_data_fetcher`, `text_metrics`

**Data Sources**
- Yahoo Finance (market data)
- SEC EDGAR (10â€‘K filings)
- News APIs / scraping

**Architecture**
- Modular, classâ€‘based design
- Configâ€‘driven parameters (`config.py`)
- Clear separation of concerns for maintainability

**Setup**
- **Note:** This project was developed and tested on Pythonâ€¯3.11.9.  
- Using a different Python version may cause dependency or compatibility issues.

---

## ğŸ“‚ Project Structure
```
. 
  â”œâ”€â”€ main.py                   # Orchestrates the full pipeline 
  â”œâ”€â”€ config.py                 # Centralized configuration 
  â”œâ”€â”€ data_fetcher.py           # Market data retrieval 
  â”œâ”€â”€ portfolio_analysis.py     #  Portfolio simulation & risk metrics 
  â”œâ”€â”€ news_analysis.py          # Headline sentiment analysis 
  â”œâ”€â”€ sec_data_fetcher.py       # SEC filings retrieval & filtering 
  â”œâ”€â”€ text_metrics.py           # NLP metrics on 10-K filings 
  â”œâ”€â”€ data/ 
  â”‚ â”œâ”€â”€ raw/                    # Unprocessed data (filings, raw CSVs) 
  â”‚ â”œâ”€â”€ processed/              # Cleaned datasets & metrics 
  â”‚ â””â”€â”€ reference/              # LM dictionaries
  â”œâ”€â”€ ml_train.py               # ML training, evaluation, and portfolio simulation
  â”œâ”€â”€ feature_engineering.py    # Builds features from base + partner ticker
  â”œâ”€â”€ data_splits.py            # Train/holdout split logic
  â”œâ”€â”€ model_selection.py        # Model tuning, ranking, and export
  â”œâ”€â”€ portfolio_sim.py          # Long-short and buy-hold simulation
  â””â”€â”€ README.md                 # Project documentation
```
---

## ğŸš€ How to Run

1. **Clone the repo**
   ```bash
   git clone https://github.com/yourusername/dowjones_nlp_pipeline.git
   cd dowjones_nlp_pipeline
   
2. Install dependencies
   pip install -r requirements.txt
   
3. Configure parameters in config.py
  - Date ranges (START_DATE, END_DATE, PREDICTION_YEAR)
  - SEC filings path
  - Dow Jones tickers URL
  - Base Ticker choice

4. Run the pipeline
   python main.py

## ğŸ“œ License
This project is for educational and portfolio purposes. Data sources are subject to their respective terms of use.

## ğŸ‘¤ About Me
KRMayoi - Data science & analytics enthusiast, focused on reproducible, modular pipelines and the intersection of NLP with financial markets.
